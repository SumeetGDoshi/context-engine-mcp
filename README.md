# Context Engine MCP Server

> Stop wasting 50% of your AI-generated code. Ship production-ready code on the first try.

An MCP (Model Context Protocol) server that automates the **Research ‚Üí Plan ‚Üí Validate** workflow for AI coding tools like Cursor, Claude Code, and Copilot.

## üéØ The Problem

The Stanford study found that **50% of AI-generated code needs to be rewritten**. Why?

- Developers skip research and jump straight to coding
- No detailed planning before implementation
- No systematic validation after coding
- AI agents lack understanding of existing codebase

**Result**: Lots of code that doesn't fit the architecture, breaks patterns, or solves the wrong problem.

## üí° The Solution

Context Engine enforces a proven workflow:

```
1. üîç Research  ‚Üí Understand existing codebase first
2. üìã Plan      ‚Üí Specify every change before coding  
3. ‚úÖ Validate  ‚Üí Verify implementation matches spec
```

This is the workflow that enabled:
- **35k lines of code shipped in one day** (Boundary use case)
- **Zero rework** on 300k line Rust codebase (BAML case study)
- **2 PRs on first day** for engineering interns

[Watch Dex's talk](https://www.youtube.com/watch?v=IS_y40zY-hc) explaining the methodology.

## üöÄ Quick Start

### Installation

```bash
npm install -g @context-engine/mcp-server
```

### Configure with Cursor

Add to your Cursor MCP settings (`~/.cursor/mcp.json`):

```json
{
  "mcpServers": {
    "context-engine": {
      "command": "npx",
      "args": ["@context-engine/mcp-server"]
    }
  }
}
```

### Configure with Claude Desktop

Add to Claude Desktop config (`~/Library/Application Support/Claude/claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "context-engine": {
      "command": "npx",
      "args": ["@context-engine/mcp-server"]
    }
  }
}
```

Restart your IDE.

## üìñ Usage

### Check Workflow Status

```
You: What's my workflow status?
```

The MCP server will tell you what phase you're in and what to do next.

### Full Workflow Example

#### 1. Research Phase

```
You: I need to add authentication to my API
```

The server will:
- ‚ùå Block immediate implementation
- ‚úÖ Guide you to research first
- ‚úÖ Generate research document at `mcpDocs/research/2025-11-16-authentication.md`
- ‚úÖ Include file:line references to existing code

#### 2. Planning Phase

After research completes:

```
You: Create implementation plan
```

The server will:
- ‚úÖ Check that research exists (or block)
- ‚úÖ Create detailed plan at `mcpDocs/plans/2025-11-16-authentication.md`
- ‚úÖ Include phases, success criteria, file changes
- ‚è∏Ô∏è Wait for your approval

#### 3. Approve Plan

Review the plan, then:

```
You: Approve the plan
```

Or if changes needed:

```
You: Reject plan - need to add rate limiting
```

#### 4. Implementation

After approval:

```
You: Implement the plan
```

The server will:
- ‚úÖ Provide implementation instructions
- ‚úÖ Reference the plan in all changes
- ‚úÖ Keep context under 40%
- ‚è∏Ô∏è Stop between phases for manual verification

#### 5. Validation

After implementation:

```
You: Validate implementation
```

The server will:
- ‚úÖ Run all automated checks from plan
- ‚úÖ Compare git diff to planned changes
- ‚úÖ Generate validation report
- ‚úÖ Report pass/fail status

## üéØ Key Features

### ‚úÖ Workflow Enforcement

**Can't skip steps:**
- No planning without research
- No implementation without approved plan
- No merge without validation

**Gentle redirection:**
```
‚ùå BLOCKED: Cannot create plan without research.

‚ö†Ô∏è  No research found. Start with research to analyze the codebase.

Please run 'research_codebase' first.
```

### üìä Workflow State Tracking

The server maintains state in `.context-engine/workflow-state.json`:

```json
{
  "currentPhase": "plan",
  "researchPath": "mcpDocs/research/2025-11-16-auth.md",
  "planPath": "mcpDocs/plans/2025-11-16-auth.md",
  "planApproved": false,
  "metadata": {
    "taskDescription": "Add authentication to API"
  }
}
```

### üé® Structured Outputs

All documents follow consistent templates:

**Research docs** include:
- What exists today (file:line references)
- How components connect
- Current patterns and conventions
- Historical context from codebase

**Implementation plans** include:
- Phased approach (Phase 1, 2, 3...)
- Specific file changes with code snippets
- Automated verification (make test, etc.)
- Manual verification (UI testing, performance)

**Validation reports** include:
- Phase-by-phase status
- Automated check results
- Deviations from plan
- Manual testing requirements

### ‚ö° Context Optimization

Following Dex's principle: **Keep context under 40%**

The server ensures:
- Research is done by parallel sub-agents
- Plans are created incrementally
- Implementation happens phase-by-phase
- Fresh context between major phases

## üèóÔ∏è Directory Structure

Context Engine creates this structure in your project:

```
your-project/
‚îú‚îÄ‚îÄ .context-engine/
‚îÇ   ‚îî‚îÄ‚îÄ workflow-state.json          # Workflow state
‚îú‚îÄ‚îÄ mcpDocs/                         # Auto-created by MCP server
‚îÇ   ‚îú‚îÄ‚îÄ research/                    # Research documents
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 2025-11-16-auth.md
‚îÇ   ‚îî‚îÄ‚îÄ plans/                       # Implementation plans
‚îÇ       ‚îî‚îÄ‚îÄ 2025-11-16-auth.md
‚îî‚îÄ‚îÄ src/                             # Your code
```

The `mcpDocs/` folder is automatically created when you start research or planning. No manual setup needed!

## üéì Understanding the Workflow

### Why This Works

From Dex's talk at AI Engineer Summit:

> "A bad line of code is a bad line of code. But a bad part of a plan can be hundreds of bad lines of code. And a bad line of research‚Äîa misunderstanding of how the system works‚Äîcan be thousands of bad lines of code."

**The hierarchy:**
1. **Bad research** ‚Üí 1000s of bad lines
2. **Bad plan** ‚Üí 100s of bad lines
3. **Bad code** ‚Üí 1 bad line

**Invest time at the top of the hierarchy.**

### Context is Everything

LLMs are pure functions. The ONLY thing that affects output quality is input quality (context).

**Goal**: Keep context utilization under 40%

**Why?** The less context used, the better the results. By:
- Researching first (parallel agents)
- Planning before coding
- Compacting between phases

You maximize the "tokens available for thinking" at each step.

### Spec-First Development

In the AI future, **specifications are the valuable asset**, not the generated code.

- Code can be regenerated from spec
- Specs capture intent and decisions
- Specs enable mental alignment across teams
- Specs prevent rework

Context Engine treats plans as first-class artifacts.

## üõ†Ô∏è Advanced Usage

### Custom Research Agents

The research phase spawns parallel agents:
- `codebase-locator` - Finds files and components
- `codebase-analyzer` - Understands how code works
- `codebase-pattern-finder` - Finds similar implementations
- `thoughts-locator` - Searches historical decisions

### Success Criteria Format

Plans must separate automated vs manual verification:

```markdown
### Success Criteria:

#### Automated Verification:
- [ ] Tests pass: `make test`
- [ ] Linting passes: `make lint`
- [ ] Build succeeds: `make build`

#### Manual Verification:
- [ ] UI works correctly when tested
- [ ] Performance acceptable under load
- [ ] No regressions in related features
```

This enables:
- Automated validation to run checks
- Clear handoff for manual testing
- Phase-by-phase verification

### Context Compaction

When context approaches 40%, the implementation phase:
1. Updates plan with progress checkmarks
2. Notes current state and next steps
3. Starts fresh context with updated plan

This maintains high-quality outputs throughout implementation.

## üìä Metrics & Analytics

Context Engine tracks:

- **Workflow adherence** - % of tasks following proper workflow
- **Rework prevented** - Estimated hours saved
- **Context efficiency** - Average context utilization
- **First-try success** - % of implementations passing validation

(Pro/Enterprise features - coming soon)

## ü§ù Integration with Other Tools

### GitHub Actions

Validate PRs automatically:

```yaml
# .github/workflows/validate-workflow.yml
name: Validate Workflow

on: pull_request

jobs:
  check-workflow:
    runs-on: ubuntu-latest
    steps:
      - name: Check for plan
        run: |
          grep -q "mcpDocs/plans/" PR_DESCRIPTION || exit 1
      
      - name: Run validation
        run: |
          npx @context-engine/mcp-server validate
```

### Pre-commit Hooks

Enforce plan references in commits:

```bash
#!/bin/bash
# .git/hooks/commit-msg

if ! grep -q "Plan:" "$1"; then
    echo "‚ùå Commit must reference implementation plan"
    echo "Format: 'Plan: mcpDocs/plans/2025-11-16-feature.md'"
    exit 1
fi
```

### Linear/Jira Integration

Link research and plans to tickets automatically.

## üó∫Ô∏è Roadmap

### v0.1 (Current)
- ‚úÖ Core MCP server
- ‚úÖ Workflow state management
- ‚úÖ Research/Plan/Validate tools
- ‚úÖ Cursor/Claude integration

### v0.2 (Next)
- [ ] Analytics dashboard
- [ ] Team collaboration features
- [ ] Cloud sync for documents
- [ ] Slack/Discord integration

### v1.0 (Future)
- [ ] Enterprise SSO/SAML
- [ ] Custom workflow templates
- [ ] Advanced metrics & insights
- [ ] API for integrations

## ü§ù Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.
We welcome support buymeacoffee.com/thecodershow

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

## üí¨ Support

- **Issues**: [GitHub Issues](https://github.com/context-engine/mcp-server/issues)

## üôè Acknowledgments

Built on the workflow pioneered by:
- [Dex](https://twitter.com/dexhorthy) and the Human Layer team
- The [MCP](https://modelcontextprotocol.io) team at Anthropic
- The AI engineering community

---

**Stop wasting 50% of your AI code. Start using Context Engine today.**

```bash
npm install -g @contexter/mcp-server
```
